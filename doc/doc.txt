1. Variational Autoencoder (VAE)
优点：

训练稳定：目标函数包含重构误差和 KL 散度，梯度平滑，不易崩溃。

隐空间连续且有意义：编码器-解码器架构可直接对潜在空间做插值或属性运算。

易于推断：能够直接对给定数据编码出潜在向量，便于下游任务（如异常检测）。

缺点：

样本模糊：极大似然目标鼓励覆盖全分布，重构结果往往偏向平均值，图像/样本不够锐利。

生成样本质量有限：对复杂高维分布建模能力不如 GAN。

2. Generative Adversarial Network (GAN)
优点：

高保真度样本：对抗训练能生成非常真实、细节丰富的样本（尤其在图像领域）。

灵活性强：架构可扩展、可结合自注意力、卷积、条件输入等多种技术。

缺点：

训练不稳定：易出现梯度消失、模式崩溃（mode collapse）等问题。

无显式似然函数：无法直接评估生成样本的概率，难以做概率推断或下游统计分析。

3. Wasserstein GAN (WGAN)
优点：

改进的训练稳定性：使用 Wasserstein 距离替代 JS 散度，提供更平滑的损失曲线。

缓解模式崩溃：在大多数场景下显著减少 mode collapse。

易于监控训练：损失值与生成质量更具相关性，可直观判断收敛情况。

缺点：

梯度裁剪或梯度惩罚的超参敏感：需要对权重裁剪范围或梯度惩罚系数进行调优。

训练速度相对较慢：每轮更新中判别器更新次数通常多于生成器，且计算 Wasserstein 距离开销更大。

4. Conditional Tabular GAN (CTGAN)
优点：

专为表格数据设计：天然支持混合连续与离散特征；通过条件向量（conditional vector）解决类不平衡问题。

模式特定归一化：对每个类别下的连续特征分别归一化，避免多模态分布失真。

生成高质量的合成表格数据：在强类别不平衡和复杂相关性场景中表现优异。

缺点：

只针对表格数据：架构和归一化策略不适用于图像、音频等其它数据类型。

实现和调参复杂度更高：需要指定哪些字段作为条件，训练时多一次采样分类、归一化等步骤。

继承了 GAN 的不稳定性：尽管有所改进，但训练仍可能出现判别器与生成器不平衡的问题。